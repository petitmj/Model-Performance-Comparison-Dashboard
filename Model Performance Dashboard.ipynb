{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8210b6c1",
   "metadata": {},
   "source": [
    "# Model Performance Dashboard\n",
    "\n",
    "\n",
    "This notebook provides a modularized version of the Model Performance Dashboard. The goal is to evaluate the effectiveness of the model on the dataset. It covers data upload, preprocessing, model selection, training, and evaluation using various machine learning models. AWS S3 integration is included for dataset management.\n",
    "\n",
    "\n",
    "Key features include:\n",
    "\n",
    "- Support for both local and AWS S3 data sources for flexible dataset management.\n",
    "- Interactive widgets for uploading data, selecting the target column and model, and displaying results.\n",
    "- Evaluation metrics such as accuracy, F1 score, and ROC AUC to assess model performance.\n",
    "- Data preprocessing steps including handling missing values, feature scaling, and train/test splitting.\n",
    "\n",
    "\n",
    "This notebook is designed to help users easily experiment with different models and datasets in an interactive environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9336956b",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "Import all necessary libraries for data handling, AWS S3, and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4100492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "from io import BytesIO\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "print(\"All libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea494a58",
   "metadata": {},
   "source": [
    "## 2. AWS S3 Configuration and Helper Functions\n",
    "Set up AWS S3 configuration and define helper functions for file management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "949b1f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 storage client configured successfully.\n"
     ]
    }
   ],
   "source": [
    "# AWS S3 Configuration\n",
    "S3_BUCKET_NAME = \"arv7staging\"\n",
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "def s3_file_exists(s3_key):\n",
    "    try:\n",
    "        s3_client.head_object(Bucket=S3_BUCKET_NAME, Key=s3_key)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "print(\"S3 storage client configured successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f87c692",
   "metadata": {},
   "source": [
    "## 3. Dataset Upload and Download from S3\n",
    "Functions to upload local datasets to S3 and load datasets from S3, supporting CSV and XLSX formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58887aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_s3(local_path, s3_key):\n",
    "    if os.path.exists(local_path):\n",
    "        if not s3_file_exists(s3_key):\n",
    "            with open(local_path, \"rb\") as f:\n",
    "                s3_client.put_object(Bucket=S3_BUCKET_NAME, Key=s3_key, Body=f)\n",
    "            print(f\"Uploaded {s3_key} to S3.\")\n",
    "        else:\n",
    "            print(f\"Skipping {s3_key}: Already exists in S3.\")\n",
    "    else:\n",
    "        print(f\"Error: {local_path} does not exist.\")\n",
    "\n",
    "def load_from_s3(s3_key):\n",
    "    try:\n",
    "        obj = s3_client.get_object(Bucket=S3_BUCKET_NAME, Key=s3_key)\n",
    "        if s3_key.endswith(\".csv\"):\n",
    "            df = pd.read_csv(obj['Body'], low_memory=False)\n",
    "        elif s3_key.endswith(\".xlsx\"):\n",
    "            df = pd.read_excel(BytesIO(obj['Body'].read()), engine='openpyxl')\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file format\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {s3_key} from S3: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e745d117",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing Function\n",
    "Define a function to preprocess the data, including selecting numeric columns, imputing missing values, scaling features, and splitting into train/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef443638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, target_column):\n",
    "    if target_column not in df.columns:\n",
    "        raise ValueError(f\"Target column '{target_column}' not found in dataset.\")\n",
    "    df = df.select_dtypes(include=[np.number])  # Keep only numeric columns\n",
    "    if target_column not in df.columns:\n",
    "        raise ValueError(f\"After processing, target column '{target_column}' is missing.\")\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_imputed)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a749485b",
   "metadata": {},
   "source": [
    "## 5. Model Definitions\n",
    "Create a dictionary of available models: Logistic Regression, Random Forest, HistGradientBoosting, XGBoost, LightGBM, CatBoost, K-Nearest Neighbors, and MLP Neural Network. Models can be selected for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de583b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "    \"HistGradientBoosting\": HistGradientBoostingClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    \"LightGBM\": LGBMClassifier(),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"MLP Neural Network\": MLPClassifier(max_iter=500)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a423cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store outcomes for each model\n",
    "model_outcomes = {}\n",
    "\n",
    "\n",
    "def store_model_outcome(model_name, y_true, y_pred, y_proba):\n",
    "    outcome = {\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"F1 Score\": f1_score(y_true, y_pred),\n",
    "        \"ROC AUC\": roc_auc_score(y_true, y_proba) if y_proba is not None else \"N/A\"\n",
    "    }\n",
    "    model_outcomes[model_name] = outcome\n",
    "    return outcome\n",
    "\n",
    "\n",
    "def compare_model_outcomes():\n",
    "    return model_outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1c66f2",
   "metadata": {},
   "source": [
    "## 6. Load and Preview Dataset\n",
    "Load a dataset from a local file or S3, and display a preview of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12a19c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a23dbd3e645c4192aeb4b30d20418053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.csv,.xlsx', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# File upload widget\n",
    "file_upload = widgets.FileUpload(accept='.csv,.xlsx', multiple=False)\n",
    "display(file_upload)\n",
    "\n",
    "def get_uploaded_df(file_upload):\n",
    "    if len(file_upload.value) > 0:\n",
    "        uploaded_filename = list(file_upload.value.keys())[0]\n",
    "        content = file_upload.value[uploaded_filename]['content']\n",
    "        if uploaded_filename.endswith('.csv'):\n",
    "            df = pd.read_csv(BytesIO(content))\n",
    "        elif uploaded_filename.endswith('.xlsx'):\n",
    "            df = pd.read_excel(BytesIO(content), engine='openpyxl')\n",
    "        else:\n",
    "            raise ValueError('Unsupported file format')\n",
    "        return df\n",
    "    return None\n",
    "\n",
    "df = get_uploaded_df(file_upload)\n",
    "if df is not None:\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65e75f7",
   "metadata": {},
   "source": [
    "## 7. Select Target Column and Models\n",
    "Allow user to select the target column and one or more models to compare using ipywidgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63aab3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    target_selector = widgets.Dropdown(options=df.columns.tolist(), description='Target Column:')\n",
    "    model_selector = widgets.SelectMultiple(options=list(models.keys()), description='Models to Compare:', value=[list(models.keys())[0], list(models.keys())[1]])\n",
    "    display(target_selector, model_selector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e632596",
   "metadata": {},
   "source": [
    "## 8. Train and Evaluate Selected Models\n",
    "Train the selected models on the preprocessed data, make predictions, and evaluate performance using accuracy, F1 score, and ROC AUC. Results for all selected models are compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "920d7e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = preprocess_data(df, target_selector.value)\n",
    "        for model_name in model_selector.value:\n",
    "            model = models[model_name]\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "            store_model_outcome(model_name, y_test, y_pred, y_proba)\n",
    "        print(\"Model Performance Comparison:\")\n",
    "        print(compare_model_outcomes())\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
